# -*- coding: utf-8 -*-
"""customar_sales.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OubG0s1mCj3EaEFlGAEsHc-uXQg0FLaS

# **Day** **1**: **Setup**, **Loading**, **Exploration**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use("seaborn-v0_8")
pd.set_option("display.max_columns", None)

"""**#Load** **data**"""

sales_df = pd.read_csv("sales_data.csv")
churn_df = pd.read_csv("customer_churn.csv")

"""**#Quick** **exploration**"""

print("Sales head:")
print(sales_df.head())
print("\nSales info:")
print(sales_df.info())

print("\nChurn head:")
print(churn_df.head())
print("\nChurn info:")
print(churn_df.info())

"""**#Check** **missing** **values**"""

print("\nMissing values (sales):")
print(sales_df.isna().sum())
print("\nMissing values (churn):")
print(churn_df.isna().sum())

"""# **Day** **2**: **Cleaning** & **Preparation**

**#Strip** and standardize text columns
"""

text_cols_sales = sales_df.select_dtypes(include="object").columns
sales_df[text_cols_sales] = sales_df[text_cols_sales].apply(
    lambda col: col.str.strip().str.lower()
)

text_cols_churn = churn_df.select_dtypes(include="object").columns
churn_df[text_cols_churn] = churn_df[text_cols_churn].apply(
    lambda col: col.str.strip().str.lower()
)

"""**#Convert** **date** **column** :
Change 'order_date' to your real date column name
"""

sales_df["Date"] = pd.to_datetime(sales_df["Date"], errors="coerce")

"""**#Handle** missing values"""

for col in ["quantity", "price"]:
    if col in sales_df.columns:
        sales_df[col] = sales_df[col].fillna(0)

sales_df = sales_df.dropna(subset=["Date", "Customer_ID"])

"""**#Create** **calculated** **columns**
: Revenue = quantity * price
"""

sales_df["revenue"] = sales_df["Quantity"] * sales_df["Price"]

sales_df["year"] = sales_df["Date"].dt.year
sales_df["month"] = sales_df["Date"].dt.month
sales_df["day"] = sales_df["Date"].dt.day
sales_df["year_month"] = sales_df["Date"].dt.to_period("M").astype(str)

print("\nSales with new columns:")
print(sales_df.head())

"""# **Day** **3**: **Customer** **Analysis**

**#Merge** sales with customers to get customer attributes
: Make sure 'customer_id' exists in both
"""

sales_df = sales_df.rename(columns={'Customer_ID': 'customer_id'})
churn_df = churn_df.rename(columns={'CustomerID': 'customer_id'})

full_df = pd.merge(
    sales_df,
    churn_df,
    on="customer_id",
    how="left",
    suffixes=('_sale', '_cust'),
)

print("\nMerged data head:")
print(full_df.head())

"""**#Customer**-level aggregations"""

customer_agg = (
    full_df.groupby("customer_id")
    .agg(
        total_revenue=("revenue", "sum"),
        order_count=("Date", "count"),
        total_quantity=("Quantity", "sum"),
        first_purchase=("Date", "min"),
        last_purchase=("Date", "max"),
        region=("Region", "first"),
    )
    .reset_index()
)

customer_agg["avg_order_value"] = customer_agg["total_revenue"] / customer_agg["order_count"]

print("\nCustomer-level metrics:")
print(customer_agg.head())

"""**#Identify** top customers"""

top_customers = customer_agg.sort_values("total_revenue", ascending=False).head(10)
print("\nTop 10 customers by revenue:")
print(top_customers)

"""**#Regional** distribution of customers"""

region_customer_counts = customer_agg["region"].value_counts()
print("\nCustomer counts by region:")
print(region_customer_counts)

"""# **Day** **4**: **Sales** **Pattern** **Analysis**

**#Monthly** revenue
"""

monthly_revenue = (
    full_df.groupby("year_month")
    .agg(
        total_revenue=("revenue", "sum"),
        order_count=("Date", "count"),
        total_quantity=("Quantity", "sum"),
    )
    .reset_index()
)

print("\nMonthly revenue summary:")
print(monthly_revenue.head())

# ---- Best-selling products
product_agg = (
    full_df.groupby("Product")
    .agg(
        total_revenue=("revenue", "sum"),
        total_quantity=("Quantity", "sum"),
        order_count=("Date", "count"),
    )
    .reset_index()
)
best_products = product_agg.sort_values("total_revenue", ascending=False).head(10)
print("\nTop 10 products by revenue:")
print(best_products)

"""**#Regional** performance"""

if "region_sale" in full_df.columns:
    region_col = "region_sale"
elif "region" in full_df.columns:
    region_col = "region"
else:
    region_col = None

if region_col:
    region_sales = (
        full_df.groupby(region_col)
        .agg(
            total_revenue=("revenue", "sum"),
            order_count=("order_id", "nunique"),
            total_quantity=("quantity", "sum"),
        )
        .reset_index()
    )
    print("\nSales by region:")
    print(region_sales)

"""# **Day** **5**: **Advanced** **Analysis**

**#Pivot** tables
: Revenue by region and month
"""

if region_col:
    pivot_region_month = pd.pivot_table(
        full_df,
        values="revenue",
        index=region_col,
        columns="year_month",
        aggfunc="sum",
        fill_value=0,
    )
    print("\nRevenue by region and month (pivot):")
    print(pivot_region_month)

"""**#Revenue** by region and product category"""

if region_col and "category" in full_df.columns:
    pivot_region_cat = pd.pivot_table(
        full_df,
        values="revenue",
        index=region_col,
        columns="category",
        aggfunc="sum",
        margins=True,
        margins_name="total",
        fill_value=0,
    )
    print("\nRevenue by region and category (pivot):")
    print(pivot_region_cat)

"""**#Multiple** aggregations in pivot"""

if "category" in full_df.columns:
    pivot_multi = pd.pivot_table(
        full_df,
        values=["revenue", "quantity"],
        index="category",
        aggfunc={"revenue": ["sum", "mean"], "quantity": "sum"},
        fill_value=0,
    )
    print("\nCategory pivot with multiple aggregations:")
    print(pivot_multi)

"""**#Cross**-**selling**: products that sell together in the same order"""

def get_product_pairs(df):
    pairs_list = []
    # Create a synthetic order_id by grouping by customer_id and Date
    # This assumes that all items bought by the same customer on the same day are part of one order
    df_copy = df.copy()
    df_copy['synthetic_order_id'] = df_copy['customer_id'].astype(str) + '_' + df_copy['Date'].dt.strftime('%Y%m%d')

    grouped = df_copy.groupby("synthetic_order_id")["Product"].apply(list)
    for products in grouped:
        unique_products = sorted(set(products))
        if len(unique_products) < 2:
            continue
        for i in range(len(unique_products)):
            for j in range(i + 1, len(unique_products)):
                pairs_list.append((unique_products[i], unique_products[j]))
    return pairs_list

product_pairs = get_product_pairs(full_df)
pairs_df = pd.DataFrame(product_pairs, columns=["product_a", "product_b"])
pair_counts = (
    pairs_df.value_counts()
    .reset_index(name="pair_count")
    .sort_values("pair_count", ascending=False)
)
top_pairs = pair_counts.head(10)
print("\nTop product pairs (cross-sell candidates):")
print(top_pairs)

"""**#Retention** (repeat purchase) and churn
: Repeat purchase rate (simple retention proxy)
"""

repeat_customers = customer_agg[customer_agg["order_count"] > 1].shape[0]
total_customers = customer_agg.shape[0]
repeat_rate = repeat_customers / total_customers if total_customers > 0 else np.nan
print(f"\nRepeat purchase rate: {repeat_rate:.2%}")

# If churn_df has columns ['customer_id', 'churned'], compute churn rate
if "churned" in churn_df.columns:
    churn_merged = pd.merge(customer_agg, churn_df, on="customer_id", how="left")
    churn_rate = churn_merged["churned"].mean()
    print(f"Churn rate (from churn_df): {churn_rate:.2%}")

"""# **Day** **6**: **Dashboard** **Visualizations**

Monthly revenue trend
"""

plt.figure(figsize=(10, 5))
monthly_revenue_sorted = monthly_revenue.sort_values("year_month")
plt.plot(monthly_revenue_sorted["year_month"], monthly_revenue_sorted["total_revenue"], marker="o")
plt.xticks(rotation=45)
plt.title("Monthly Revenue Trend")
plt.xlabel("Year-Month")
plt.ylabel("Revenue")
plt.tight_layout()
plt.show()

"""Top 10 customers by revenue"""

plt.figure(figsize=(10, 5))
top_customers_plot = top_customers.sort_values("total_revenue")
plt.barh(top_customers_plot["customer_id"], top_customers_plot["total_revenue"])
plt.title("Top 10 Customers by Revenue")
plt.xlabel("Revenue")
plt.ylabel("Customer")
plt.tight_layout()
plt.show()

"""Revenue by region"""

if region_col:
    plt.figure(figsize=(8, 5))
    sns.barplot(
        data=region_sales.sort_values("total_revenue", ascending=False),
        x="total_revenue",
        y=region_col,
    )
    plt.title("Revenue by Region")
    plt.xlabel("Revenue")
    plt.ylabel("Region")
    plt.tight_layout()
    plt.show()

"""Revenue by product category"""

if "category" in full_df.columns:
    category_revenue = (
        full_df.groupby("category")["revenue"].sum().sort_values(ascending=False)
    )
    plt.figure(figsize=(8, 5))
    sns.barplot(
        x=category_revenue.values,
        y=category_revenue.index,
    )
    plt.title("Revenue by Product Category")
    plt.xlabel("Revenue")
    plt.ylabel("Category")
    plt.tight_layout()
    plt.show()

"""Heatmap of region vs month (from pivot)"""

if region_col:
    plt.figure(figsize=(10, 6))
    sns.heatmap(pivot_region_month, annot=False, cmap="Blues")
    plt.title("Revenue Heatmap: Region vs Month")
    plt.xlabel("Year-Month")
    plt.ylabel("Region")
    plt.tight_layout()
    plt.show()

"""# **Day** **7**: **Basic** **printed** **KPIs**"""

total_revenue = full_df["revenue"].sum()
total_customers_kpi = customer_agg["customer_id"].nunique()
# Calculate total number of unique orders by considering unique customer_id and Date combinations
total_unique_orders = full_df[['customer_id', 'Date']].drop_duplicates().shape[0]
avg_order_value = total_revenue / total_unique_orders

top_customer_row = top_customers.iloc[0]
top_customer_name = top_customer_row["customer_id"] # Corrected from 'customer_name'
top_customer_revenue = top_customer_row["total_revenue"]

print("\n===== CUSTOMER SALES ANALYSIS REPORT (KPI SUMMARY) ====")
print(f"Total Revenue: {total_revenue:,.2f}")
print(f"Total Customers: {total_customers_kpi:,}")
print(f"Average Order Value: {avg_order_value:,.2f}")
print(f"Top Customer: {top_customer_name} - {top_customer_revenue:,.2f}")
print(f"Repeat Purchase Rate: {repeat_rate:.2%}")
if "churn" in churn_df.columns: # Check for 'churn' column in churn_df
    # Recalculate churn_rate if not already done, or ensure it's available
    if 'churn_merged' in locals() and 'Churn' in churn_merged.columns:
        churn_rate = churn_merged["Churn"].mean()
        print(f"Churn Rate: {churn_rate:.2%}")
    elif 'Churn' in churn_df.columns: # Fallback if churn_merged wasn't correctly processed or needed directly from churn_df
        # Need to ensure that churn_df contains unique customer_ids if we're directly using its 'Churn' column for an overall rate
        # For this specific KPI, it's safer to base it off the original churn_df as it represents customer churn status
        # Assuming 'Churn' column is 0/1 indicating non-churn/churn
        churn_rate_from_df = churn_df['Churn'].mean()
        print(f"Churn Rate: {churn_rate_from_df:.2%}")